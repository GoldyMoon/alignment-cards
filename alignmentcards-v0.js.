// data.js

export const categories = [
  {
    code: "AP",
    name: "Alignment Principles",
    pathology: "normative void",
    color: "#E6FFE9",
    description:
      "Alignment principles are contestable, general-purpose, broadly recognized ethical or social or normative commitments that can serve as warrants for recommending or evaluating an agent's course of action in contexts where alignment and cooperation with others matters."
  },
  {
    code: "AB",
    name: "Alignment by Incentives",
    pathology: "reward hacking",
    color: "#E6F0FF",
    description:
      "Focuses on how incentive structures shape behavior and whether they align with desired ethical or organizational goals."
  },
  {
    code: "EXAMPLE01",
    name: "Examples",
    pathology: "n/a",
    color: "#FFF5E6",
    description: "Example alignment and failure scenarios."
  }
];

export const cards = [
  {
    category: "AP",
    name: "Beneficence",
    definition: "Act to promote the well-being of others.",
    human: "Seeking to improve others' conditions, not just avoid harm.",
    organizational: "Pursuing mission outcomes that serve societal good.",
    professional:
      "Keeping public safety and welfare in sight even while working primarily for the client.",
    machine:
      "Designing systems that anticipate and promote human flourishing.",
    failureModes: {
      human:
        "A person drives in a manner that causes traffic backups for others.",
      organizational:
        "The classic movie plot where a rapacious billionaire threatens civilization to enrich his company.",
      professional:
        "An expert who disregards public interest, acting as if the consequences of what they help build are other people's problems.",
      machine:
        "The machine consumes all the world's resources to create as many paperclips as it can."
    }
  },
  {
    category: "AP",
    name: "TEMPLATE 1",
    definition: "basic definition that works across four domains",
    human: "BRIEFLY: how does it manifest in the human intelligence alignment context?",
    organizational: "BRIEFLY: how does it manifest in the organizational intelligence alignment context?",
    professional: "BRIEFLY: how does it manifest in the expert intelligence alignment context?",
    machine: "BRIEFLY: how does it manifest in the machine intelligence alignment context?",
    failureModes: {
      human: "Give concrete example(s).",
      organizational: "Give concrete example(s).",
      professional: "Give concrete example(s).",
      machine: "Give concrete example(s)."
    }
  },
  {
    category: "AB",
    name: "Incentive Coherence",
    definition: "Rewards should reinforce the behaviors and outcomes the organization truly values.",
    human: "Align your praise and rewards with what you actually want others to do, not just whatâ€™s easiest to observe.",
    organizational: "Design reward systems so that performance evaluations, promotions, and bonuses reflect desired goals rather than proxy metrics.",
    professional: "Structure recognition and compensation to reward the ethical, diligent, or collaborative work the profession claims to value.",
    machine: "Ensure feedback signals and reward functions align with the true objective, not an imperfect measurable proxy.",
    failureModes: {
      human: "A parent says they value honesty but only rewards obedience.",
      organizational: "A firm claims to value teamwork but promotes individual sales totals.",
      professional: "An academic department claims to value teaching but rewards publication counts.",
      machine: "An AI trained to maximize clicks learns to spread sensational misinformation."
    }
  },
  {
    category: "AB",
    name: "Temporal Alignment",
    definition: "Match the timing of rewards to the timescale of desired outcomes.",
    human: "Encourage long-term commitments rather than instant gratification.",
    organizational: "Design incentives that reward sustainable performance and learning, not just quarterly results.",
    professional: "Recognize mentoring, research quality, or ethical diligence that pay off over time.",
    machine: "Avoid short-term reward signals that discourage exploration or long-term safety.",
    failureModes: {
      human: "Students cram for exams instead of building lasting understanding.",
      organizational: "Executives maximize quarterly profit at the expense of long-term resilience.",
      professional: "Engineers rush deliverables to meet immediate metrics, creating future maintenance debt.",
      machine: "A reinforcement learner over-optimizes short-term gains and fails catastrophically later."
    }
  },
  {
    category: "EXAMPLE01",
    name: "Acceptable Failure",
    definition: "Design systems that reward responsible risk-taking and learning rather than punishing all mistakes.",
    human: "People grow courageous and creative when error is treated as part of learning rather than as disobedience or incompetence.",
    organizational: "Organizations foster adaptability when they tolerate and analyze small failures instead of punishing them, encouraging initiative and innovation.",
    professional: "Experts improve practice and safety when near misses are reported, studied, and used to refine standards instead of being hidden to avoid blame.",
    machine: "AI systems become safer when allowed to explore and learn from bounded errors during training rather than being rigidly penalized for deviation.",
    failureModes: {
      human: "A child avoids taking initiative because parents punish every mistake rather than praising effort and learning.",
      organizational: "A company culture discourages experimentation by punishing any deviation from protocol.",
      professional: "Doctors hide minor errors to avoid sanctions instead of reporting them to improve systemic safety.",
      machine: "A reinforcement learner trained with heavy penalties for any wrong move becomes overly conservative and fails to explore better strategies."
    }
  }
];
